const tx = (ar, en) => ({ ar, en });

export const REGRESSION_INTRO_SLIDES = [
  {
    id: "question",
    title: tx("Ø§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", "Foundational Question"),
    subtitle: tx(
      "Ø¹Ù†Ø¯Ù…Ø§ ØªÙƒÙˆÙ† Ù„Ø¯ÙŠÙ†Ø§ Ù†Ù‚Ø§Ø· Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¨Ø¹Ø«Ø±Ø©ØŒ ÙƒÙŠÙ Ù†Ø¨Ù†ÙŠ Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ ÙŠÙØ³Ø± Ø§Ù„Ø¹Ù„Ø§Ù‚Ø© Ø¨ÙŠÙ†Ù‡Ø§ØŸ",
      "When points are scattered, how can we build a model that captures their relationship?"
    ),
    bullets: [
      tx("Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ ÙŠÙ„Ø§Ø¦Ù… Ø§Ù„Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø¹Ø§Ù… Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª.", "Linear regression fits the global trend."),
      tx("Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ ÙŠØ­ÙˆÙ„ Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¥Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„ ÙˆØªØµÙ†ÙŠÙ.", "Logistic regression turns prediction into probability and classification.")
    ],
    visual: {
      type: "scatter"
    }
  },
  {
    id: "linear",
    title: tx("Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ø®Ø·ÙŠ", "Linear Regression"),
    equation: "Å· = wx + b",
    bullets: [
      tx("w ÙŠØ­Ø¯Ø¯ Ø§Ù„Ù…ÙŠÙ„ØŒ Ùˆ b ÙŠØ­Ø¯Ø¯ Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø±Ø£Ø³ÙŠØ©.", "w controls slope, b controls vertical shift."),
      tx("Ù†Ù‚Ù„Ù„ Ø§Ù„ÙØ±ÙˆÙ‚ Ø§Ù„Ø±Ø£Ø³ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ§Ù„Ø®Ø· (Residuals).", "We minimize vertical residuals between points and the line.")
    ],
    visual: {
      type: "regression"
    }
  },
  {
    id: "logistic",
    title: tx("Ø§Ù„Ø§Ù†Ø­Ø¯Ø§Ø± Ø§Ù„Ù„ÙˆØ¬Ø³ØªÙŠ", "Logistic Regression"),
    equation: "p(y=1|x) = Ïƒ(wÂ·x + b)",
    bullets: [
      tx("Ø§Ù„Ù…Ø®Ø±Ø¬ Ø§Ø­ØªÙ…Ø§Ù„ Ø¨ÙŠÙ† 0 Ùˆ1.", "Output is a probability in [0,1]."),
      tx("Ø­Ø¯ Ø§Ù„Ù‚Ø±Ø§Ø± ÙŠÙØµÙ„ Ø¨ÙŠÙ† Ø§Ù„ÙØ¦Ø§Øª ÙÙŠ Ø§Ù„ÙØ¶Ø§Ø¡.", "A decision boundary separates classes in feature space.")
    ],
    visual: {
      type: "decision"
    }
  },
  {
    id: "gd",
    title: tx("Ø§Ù„ØªØ¹Ù„Ù… Ø¹Ø¨Ø± Gradient Descent", "Learning with Gradient Descent"),
    equationParts: [
      {
        label: tx("Loss", "Loss"),
        text: tx("Ù†Ù‚ÙŠØ³ Ø§Ù„Ø®Ø·Ø£ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ù†Ù…ÙˆØ°Ø¬.", "Measure current model error.")
      },
      {
        label: tx("âˆ‡Loss", "âˆ‡Loss"),
        text: tx("Ù†Ø­Ø³Ø¨ Ø§ØªØ¬Ø§Ù‡ Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø®Ø·Ø£.", "Compute direction of increasing error.")
      },
      {
        label: tx("Update", "Update"),
        text: tx("Ù†Ø­Ø¯Ù‘Ø« Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø¨Ø¹ÙƒØ³ Ø§ØªØ¬Ø§Ù‡ Ø§Ù„ØªØ¯Ø±Ø¬.", "Update parameters opposite to gradient direction.")
      },
      {
        label: tx("Repeat", "Repeat"),
        text: tx("Ù†ÙƒØ±Ø± Ø­ØªÙ‰ Ø§Ù„Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø£Ùˆ Ø§Ù„ÙˆØµÙˆÙ„ Ù„Ø®Ø·Ø£ Ù…Ù†Ø®ÙØ¶.", "Repeat until convergence or low error.")
      }
    ],
    bullets: [
      tx("Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¹Ø§Ù„ÙŠ Ù‚Ø¯ ÙŠØ³Ø¨Ø¨ ØªØ°Ø¨Ø°Ø¨Ø§Ù‹.", "High learning rates may cause oscillation."),
      tx("Ù…Ø¹Ø¯Ù„ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ù†Ø®ÙØ¶ Ø¬Ø¯Ø§Ù‹ ÙŠØ¨Ø·Ø¦ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.", "Very low learning rates slow convergence.")
    ],
    visual: {
      type: "gradient"
    }
  },
  {
    id: "generalization",
    title: tx("Ø§Ù„ØªØ¹Ù…ÙŠÙ… Ù…Ù‚Ø§Ø¨Ù„ ÙØ±Ø· Ø§Ù„ØªØ®ØµÙŠØµ", "Generalization vs Overfitting"),
    bullets: [
      tx("Ù‚Ø§Ø±Ù† Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø¨ÙŠÙ† Ø®Ø·Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ®Ø·Ø£ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±.", "Always compare train and test losses."),
      tx("Ø¥Ø°Ø§ ÙƒØ§Ù† Train Ù…Ù†Ø®ÙØ¶Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ Ùˆ Test Ù…Ø±ØªÙØ¹Ø§Ù‹ ÙÙ‡Ø°Ø§ Ù…Ø¤Ø´Ø± ÙØ±Ø· ØªØ®ØµÙŠØµ.", "Very low train loss with high test loss indicates overfitting."),
      tx("Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ¹Ù‚ÙŠØ¯ Ù„Ø§ ØªØ¹Ù†ÙŠ Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù†Ù…ÙˆØ°Ø¬Ø§Ù‹ Ø£ÙØ¶Ù„.", "More complexity does not always mean better performance.")
    ],
    note: tx("Ø§Ù„Ø¬ÙˆØ¯Ø© Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ© Ù‡ÙŠ Ø§Ù„Ø£Ø¯Ø§Ø¡ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©ØŒ Ù„Ø§ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙ‚Ø·.", "True quality is performance on unseen data, not training data alone."),
    visual: {
      type: "overfit"
    }
  },
  {
    id: "lab",
    title: tx("Ù…Ø§ Ø³ØªØ¬Ø±Ø¨Ù‡ ÙÙŠ Ø§Ù„Ù…Ø®ØªØ¨Ø±", "What You Will Explore"),
    bullets: [
      tx("Ø¥Ø¶Ø§ÙØ© Ù†Ù‚Ø§Ø· ÙŠØ¯ÙˆÙŠØ§Ù‹ ÙˆØªØ¹Ø¯ÙŠÙ„Ù‡Ø§ Ø«Ù… ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬.", "Add/edit points manually and train the model."),
      tx("Ø§Ø®ØªÙŠØ§Ø± Ù†ÙˆØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ø®ÙˆØ§Ø±Ø²Ù…ÙŠØ© ÙˆØ¯Ø§Ù„Ø© Ø§Ù„Ø®Ø³Ø§Ø±Ø©.", "Choose model type, optimizer, and loss."),
      tx("Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ø³Ø§Ø± Ø§Ù„ØªØ¹Ù„Ù… ÙˆØ§Ù„Ø³Ø·Ø­ Ø«Ù„Ø§Ø«ÙŠ Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ Ù„Ù„Ø®Ø³Ø§Ø±Ø©.", "Track learning trajectory and 3D loss surface.")
    ],
    visual: {
      type: "icon-grid",
      items: [
        {
          icon: "ğŸ–±ï¸",
          title: tx("Ø¨ÙŠØ§Ù†Ø§Øª ØªÙØ§Ø¹Ù„ÙŠØ©", "Interactive Data"),
          text: tx("Ø£Ù†Ø´Ø¦ Ø¨ÙŠØ§Ù†Ø§ØªÙƒ Ø¨Ø§Ù„Ù†Ù‚Ø± ÙˆØ§Ù„Ø³Ø­Ø¨ Ù…Ø¨Ø§Ø´Ø±Ø©.", "Create your own dataset by click-and-drag.")
        },
        {
          icon: "ğŸ“‰",
          title: tx("Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡", "Performance Metrics"),
          text: tx("Ù…Ø±Ø§Ù‚Ø¨Ø© Train/Test Ù„Ø­Ø¸ÙŠØ§Ù‹.", "Monitor train/test behavior live.")
        },
        {
          icon: "ğŸ”ï¸",
          title: tx("Ø³Ø·Ø­ Ø§Ù„Ø®Ø³Ø§Ø±Ø©", "Loss Landscape"),
          text: tx("ÙÙ‡Ù… Ø­Ø±ÙƒØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¹Ù„Ù‰ Ø³Ø·Ø­ Ø§Ù„Ø®Ø·Ø£.", "Understand parameter motion on the loss surface.")
        }
      ]
    }
  }
];
